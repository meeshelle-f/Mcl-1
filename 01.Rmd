
title: "01_"
author: "Michelle"
date: "7/2/2021"
output: html_document

https://pubmed.ncbi.nlm.nih.gov/25730472/

Data files were originally obtained from:
ftp://ftp.ncbi.nlm.nih.gov/geo/series/GSE60nnn/GSE60450/suppl/GSE60450_Lactation-GenewiseCounts.txt.gz
http://bioinf.wehi.edu.au/MSigDB/v7.1/Mm.c2.all.v7.1.entrez.rds
http://bioinf.wehi.edu.au/MSigDB/v7.1/Mm.h.all.v7.1.entrez.rds

#Step 1.Download files
Go to https://figshare.com/s/1d788fd384d33e913a2a
Download files listed below and place them into folder 'data' in working directory: 
1) GSE60450_Lactation-GenewiseCounts.txt
2) SampleInfo.txt
3)SampleInfo_Corrected.txt

```{r, load data}
#Bioconductor packages: limma, edgeR, Glimma, org.Mm.eg.db, gplots, RColorBrewer

if (!requireNamespace("BiocManager"))
    install.packages("BiocManager")
BiocManager::install(c("limma", "edgeR", "Glimma", "org.Mm.eg.db", "gplots", "RColorBrewer", "NMF", "BiasedUrn"))

library(edgeR)
library(limma)
library(Glimma)
library(org.Mm.eg.db)
library(gplots)
library(RColorBrewer)
library(NMF)

seqdata <- read.delim("~/GitHub/Mcl-1/GSE60450_LactationGenewiseCounts.txt", stringsAsFactors = FALSE)

sampleinfo = samplinfo=read.delim("~/GitHub/Mcl-1/SampleInfo_Corrected.txt",stringsAsFactors=TRUE)
sampleinfo

head(seqdata) #1 gene per row, 1st col is Entrez ID, 2nd col is gene length, there are 2 reps per cell type and time point
dim(seqdata)

sampleinfo #see more about seqdata in sampleinfo

```
 
```{r, formatting data}

#remove first 2 cols of seqdata (Entrez and length)
countdata=seqdata[,-(1:2)] #notice 2 cols are removed
rownames(countdata)=seqdata[,1] #Use entrez as row names of countdata

#reduce col names (sample names) in countdata using substr
colnames(countdata)=substr(colnames(countdata),start=1,stop=7) # extract characters starting at position 1 and stopping at position 7

#colnames of countdata now match that in sampleinfo under 'sample Name'. However we can verify this by using == 
length(table(colnames(countdata))) #table is a data frame, can use length or dim 
length(sampleinfo$SampleName) # must use length for vectors and factors and lists
colnames(countdata)==sampleinfo$SampleName 
table(colnames(countdata)==sampleinfo$SampleName) #OR convert both to a table, compare tables

```

#Step 2. Create DGEList
```{r, DGEList object for EdgeR}
#create a DGEList object used by edgeR to store count data. It has a number of slots for storing various parameters about the data.
y=DGEList(countdata)

names(y) #slots stored in DGEList object, y:  "counts"  "samples"
y$samples # Library size information is stored in the samples slot

#store the groups for the samples in the DGEList object using paste 
#paste(..., sep=" ")
#... is 1 or more R objects to be converted to character vectors 
#sep is a character string to separate terms

group <- paste(sampleinfo$CellType,sampleinfo$Status,sep=".") #converts luminal and virgin to luminal.virgin

group

group = factor(group) #convert characters to factors 
levels(group) #notice there are 6 levels of factors (which makes sense since we have 2 replicates of 6 unique cell type+status samples)

#add group info to DEGList
y$samples
y$samples$group #notice there is only 1 level for all 12 samples
y$samples$group=group 
y$samples #notice group has been changed from 1 to luminal.virgin

```
#Step 3. Gene annotations & filtering
```{r, annotation & adding gene annotation slot}
columns(org.Mm.eg.db)

#build annotation info in separate data frame using 'select' 
#y$counts row names are the ENTREZIDs
#from org.Mm.. we will extract columns "ENTREZID","SYMBOL","GENENAME"

ann=select(org.Mm.eg.db,keys=rownames(y$counts),columns=c("ENTREZID","SYMBOL","GENENAME"))
head(ann)
#check that ENTREZID col in ann matches the rownames(y$counts)
length(rownames(y$counts))
length(ann$ENTREZID)
table(rownames(y$counts)==ann$ENTREZID) #use table as it produces much shorter output

#notice y$ only has the two slots 
y$genes <- ann # slot in the annotation info into the genes slot of y. Now we there are 3 slots yay! 



```
```{r, filtering lowly expressed genes}

#genes w/low counts across the board add to the multiple testing burden when estimating FDRs and effectively reduce power to detect DEGs. Basically the more you do (inference), the more likely you'll f up (aka probability of erroneous inferences occurring increases).
#filter by min of counts per million (cpm) per 2 replicates of each sample. 
# 2 represents smallest sample size for each group in this experiment. 
# Retain genes if cpm is > .5 in at least the 2 samples. 
# Use edgeR 'cpm' function to generate and filter. Converting counts to cpm does normalize for different sequencing depths for each sample, but that is okay! 

myCPM=cpm(countdata)
head(myCPM)

# a CPM of .5 corresponds to 10-15 for library sizes in this data set. 
thresh = myCPM >.5
head(thresh) #generates logical matrix with T/F

table(rowSums(thresh)) #there are 11433 genes that have T in ALL 12 samples! Woah!

#1 sample, say basal.virgin, has 2 reps, so a total of size 2 for this 1 group. Recall that we keep a gene if at least 2 groups (total of size 4) have .5, so 4*.5=2
keep=rowSums(thresh)>=2
summary(keep) #15804 rows (genes) are true

plot(myCPM[,1],countdata[,1]) #check first sample, ensure cpm of .5 corresponds to 10-15
#plot to check linearity. recall x=myCPM
plot(myCPM[,1],countdata[,1], ylim=c(0,20),xlim=c(0,1))
abline(v=.5) # v = vertical line
abline(h=10)

y=y[keep, keep.lib.sizes=FALSE] #is this different than y[keep,]??


```
#Step 4. Quality control & normalizing  
```{r, quality control & barplot} 
#ANALYZE LIBRARY SIZES 

y$samples$lib.size #reads for each of 12 samples in y

barplot(y$samples$lib.size) #plot library sizes as a barplot
barplot(y$samples$lib.size, names=colnames(y)) #add x labels 
barplot(y$samples$lib.size, names=colnames(y),las=2, main=c("Barplot of library sizes")) #make it fit
barplot(y$samples$lib.size/1e06, names=colnames(y),las=2,main=c("Barplot of library sizes")) #adjust y axis size 

#"NORMALIZE" COUNT DATA with cpm 

logcounts=cpm(y,log=TRUE) 

boxplot(logcounts, xlab="", ylab="log2 counts per million", las=2, main=c("log-transformed, un-normalized")) #look at distributions

abline(h=median(logcounts),col="blue")#add median LogCPM 
```
#Step 5. Visualize variation
```{r, MDSplots}
#is MDS the same as PCA? 
plotMDS(y)

levels(sampleinfo$CellType) # "basal"   "luminal"
col.cell=c("purple", "orange")[sampleinfo$CellType] #purple for basal, orange for luminal 
class(col.cell) #character
data.frame(sampleinfo$CellType,col.cell) #merge the two 

plotMDS(y, col=col.cell)
legend("right",fill=c("purple", "orange"),legend=levels(sampleinfo$CellType))
title("Cell type")

#Now practice by adding blue, red and black to the sample info status ... 
levels(sampleinfo$Status)
col.status=c("blue","red","black")[sampleinfo$Status]

plotMDS(y, col=col.status) #doesn't need to be a data frame apparently to be assigned
legend("right", fill=c("blue","red","black"), legend=levels(sampleinfo$Status))
title("Status")


#now plot both sode-by side using par 

par(mfrow(c(1,2)) #plot side-by-side??? 
    
plotMDS(y, col=col.cell)
legend("right",fill=c("purple", "orange"),legend=levels(sampleinfo$CellType))
title("Cell type")


plotMDS(y, col=col.status) #doesn't need to be a data frame apparently to be assigned
legend("right", fill=c("blue","red","black"), legend=levels(sampleinfo$Status))
title("Status")
   

```
```{r, glMDS and hierachical clustering}
#html interactive MDS plot (Glimma), where the MDS plot is on the left, and the amount of variation explained by each dimension in a barplot on the right. default MDS plots shows dimensions 1 and 2.

labels=paste(sampleinfo$SampleName,sampleinfo$CellType, sampleinfo$Status)
glMDSPlot(y, labels=labels, groups=group, folder="mds")

#select data for 500 most variable genes/ plot heatmap
#first estimate variance in each row (for each gene) by making a Logcounts matrix 
dim(logcounts) # 15804    12
head(logcounts)
class(logcounts) # "matrix" "array" 

var_genes=apply(logcounts,1,var) #497097 is the first geneID
#FUN=function, take variance of rows =1

length(var_genes) #15804
head(var_genes)
class(var_genes) #numeric 

var_genes.table=as.matrix(var_genes)
var_genes.table[1,]
var(logcounts[1,])==var_genes.table[1,] #proof that variance matches 

select_var=names(sort(var_genes, decreasing =TRUE))[1:500]
head(select_var)

highly_variable_1cpm=logcounts[select_var,] #pull out 500 variables in order from most to least variance
dim(highly_variable_1cpm) #500 genes and data corresponding to all 12 samples 
head(highly_variable_1cpm)

mypalette=brewer.pal(11,"RdYlBu")
morecols=colorRampPalette(mypalette)
heatmap.2(highly_variable_1cpm,col=rev(morecols(50)),trace="none", main="Top 500 most variable genes across samples",ColSideColors=col.cell,scale="row")

# Save the heatmap
png(file="High_var_genes.heatmap.png")
heatmap.2(highly_variable_1cpm,col=rev(morecols(50)),trace="none", main="Top 500 most variable genes across samples",ColSideColors=col.cell,scale="row")

```


#Step 6. TMM normalization for composition bias

1. eliminates composition biases between libraries
2. generates a set of normalization factors, where the product of these factors & library sizes defines the effective library size. 
3. The calcNormFactors function calculates the normalization factors between libraries. 
4. TMM normalization (and most scaling normalization methods) scale relative to one sample.

See the pdf describing TMM at https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2864565/

*Reminder: y has already been "normalized" using the cpm function* 
```{r, TMM normalization}

# Apply normalization to DGEList object y using calcNormFactors
y <- calcNormFactors(y)
write.table(y$samples,file="calcNormFactorsy.txt")
y$samples #normalization factors attached for samples 


# normalization factors multiply to unity across all libraries. A normalization factor <1 indicates library size will be scaled down, as there is more suppression (i.e., composition bias) in that library relative to the other libraries. Conversely, a factor >1 scales up the library size and is equivalent to downscaling the counts. NOTICE the last 2 samples (LE, LF) have much smaller normalization factors, and MCL1.LA and MCL1.LB have the largest. 

#If we plot mean difference plots using  plotMD for these samples, we should be able to see the composition bias problem. We will use the logcounts, which have been normalized for library size, but not for composition bias like y has using calcNormFactors.

par(mfrow=c(1,2))
plotMD(logcounts,column =7)
abline(h=0,col="grey")
plotMD(logcounts,column =11)
abline(h=0,col="grey")

mean-difference plots show average expression (mean: x-axis) against log-fold-changes (difference: y-axis). 
Because our DGEList object contains the normalization factors, if we redo these plots using y, we should see the composition bias problem has been solved.

par(mfrow=c(1,2))
plotMD(y,column =7)
abline(h=0,col="grey")
plotMD(y,column =11)
abline(h=0,col="grey")


#Challenge: Plot the biased and unbiased MD plots side by side for the same sample to see the before and after TMM normalisation effect.
par(mfrow=c(2,2))
plotMD(logcounts,column =7)
abline(h=0,col="grey")
plotMD(y,column =7)
abline(h=0,col="grey")

plotMD(logcounts,column =11)
abline(h=0,col="grey")
plotMD(y,column =11)
abline(h=0,col="grey")

save(group,y,logcounts,sampleinfo,file="day1objects.Rdata")

``` 



#Step 7. Limma and Voom, create v 
The limma package (Ritchie et al. 2015 / since version 3.16.0) offers the voom function, which transforms the read counts into logCPMs *while taking into account the mean-variance relationship*. After vooming, users can apply a linear model to the voom transformed data to test for differentially expressed genes, using limma. 
```{r, design matrix}
#Identify DEGs between groups 

load("day1objects.Rdata")
objects() #6 is "group" and 20 is "y"  
group #notice the 6 levels


# Specify a design matrix without an intercept term
design <- model.matrix(~0+ group)
design

## Make the column names of the design matrix a bit nicer
colnames(design) <- levels(group)
design
```

Once we have our design matrix ready to go, we can perform our voom transformation. 
Voom automatically adjusts library sizes using the norm.factors already calculated. 
The voom transformation uses the experiment design matrix, and produces an EList object. 
Add plot=TRUE to generate a plot of the mean-variance trend. This plot can also tell us if there are any genes that look really variable in our data, and if weâ€™ve filtered the low counts adequately.
```{r, voom to create v}

par(mfrow=c(1,1))
v <- voom(y,design,plot = TRUE)
v #5 by 3 
names(v) #use names to determine what is contained within the object, v. "genes"   "targets" "E"   "weights" "design" 
v$E # voom normalized log2 counts are in v$E

#but what is the difference between v and y? Let's plot! 
#v is already log transformed. 

par(mfrow=c(1,2))

boxplot(logcounts, xlab="", ylab="Log2 counts per million",las=2,main="Unnormalised logCPM")
## add a blue horizontal line that corresponds to the median logCPM
abline(h=median(logcounts),col="blue")

boxplot(v$E, xlab="", ylab="Log2 counts per million",las=2,main="Voom transformed logCPM")
## Let's add a blue horizontal line that corresponds to the median logCPM
abline(h=median(v$E),col="blue")

```

```{r, limma}
# Fit the linear model
fit <- lmFit(v)
# lmFit estimates group means according to the design matrix, as well as gene-wise variances.
names(fit)


# Which genes are DE between pregnant & lactating group in basal cells? 
# Define the null hypothesis (Ho) as basal.pregnant - basal.lactate = 0 for each gene. 

cont.matrix <- makeContrasts(B.PregVsLac=basal.pregnant - basal.lactate,levels=design) #can pull from groups
cont.matrix

fit.cont <- contrasts.fit(fit, cont.matrix)
fit.cont <- eBayes(fit.cont)
dim(fit.cont)
summa.fit <- decideTests(fit.cont)
summary(summa.fit)

?vennDiagram
vennDiagram(summa.fit)

```

